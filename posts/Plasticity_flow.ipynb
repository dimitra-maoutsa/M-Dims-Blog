{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c088a0-ee88-4858-ab46-cdd5e71ceec9",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Plasticity flows\"\n",
    "author: \"Dimitra Maoutsa\"\n",
    "date: \"2025-05-04\"\n",
    "categories: [blog]\n",
    "description: \"Accounting for the geometry of plasticity\"\n",
    "image: images/wasser.jpg\n",
    "bibliography: references.bib\n",
    "---\n",
    "\n",
    "\n",
    "## What is a gradient flow in the probability space?\n",
    "\n",
    "\n",
    "Given some energy function $\\mathcal{E}(\\rho)$ in some probability space $\\mathcal{P}(\\Omega)$ with some metric $\\mathcal{G}(\\rho))$, $(\\mathcal{P}(\\Omega), \\mathcal{G}(\\rho))$,\n",
    "a **gradient flow** is defined as **the inverse metric times the differential of the energy function**\n",
    "\\begin{equation}\n",
    "    \\partial_t \\rho_t = -\\mathcal{G}(\\rho_t)^{-1} \\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t}.\n",
    "\\end{equation}\n",
    "Here, $\\rho_t$ is a distribution at time $t$.\n",
    "\n",
    "Intuitively, this means that the considered system of equations follows the trajectory of steepest descend on the energy functional $\\mathcal{E}(\\rho)$. To define this steepest descend we need to define the notion of the gradient. This depends on the selected geometry of the space and is computed according to the selected metric.\n",
    "\n",
    "If we consider as energy function the **Kullback Leibler divergence** $D_{KL}$, and for information metric the **Wasserstein metric** $\\mathcal{W}$, the considered gradient flow, known as **Wasserstein gradient flow**, forms the **Fokker-Planck equation**.\n",
    "\n",
    "In this case the metric inverse is $\\nabla \\cdot \\rho_t \\nabla$, and we can derive the Fokker--Planck equation as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\partial_t \\rho_t &= - \\text{grad}^{\\mathcal{W}} D_{KL}(\\rho_t ||\\rho_{ss})\\\\\n",
    "&= \\nabla \\cdot \\left(  \\rho_t \\nabla \\left( f + \\log \\rho_t +1 \\right)  \\right)\\\\\n",
    "&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\nabla \\cdot \\nabla \\rho_t\\\\\n",
    "&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\Delta \\rho_t.\n",
    "\\end{align}\n",
    "\n",
    "In the above equation we have considered that the stationary density is given by $\\rho_{ss} \\propto e^{-f}$, and that the differential of $\\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t} = \\log \\rho + f$.\n",
    "\n",
    "By considering the Benamou-Brenier formulation [@benamou2000computational],[@ambrosio2003lecture] of the Fokker-Planck dynamics we can obtain a better understanding on how the selected geometry (and metric) of the probability space influences the gradient flow dynamics. According to the Benamou-Brenier formalism the gradient flow dynamics for the Fokker-Planck equation has the following **optimal transport** interpretation:\n",
    " It describes a search over all possible vector fields $v_t$ that will transport probability mass from $\\rho_0$ to $\\rho_1$, with the Wasserstein distance capturing the minimum possible cost of this transfer. Given two probability distributions $\\rho_0$ and $\\rho_1$, we define this distance to be the minimum of the integral of the norm of the vector field $v_t$\n",
    "\\begin{equation}\n",
    "d^2_{OT} (\\rho_0, \\rho_1) = \\inf \\limits_{\\rho_t, v_t} \\int_0^1 \\| v_t \\|^2_{L^2(\\rho_t)} dt = \\mathcal{W}^2_2 (\\rho_0,\\rho_1),\n",
    "\\end{equation}\n",
    "under the constraint that the transient probability distribution $\\rho_t$ fulfils the continuity equation\n",
    "\\begin{equation}\n",
    "    \\partial_t \\rho_t + \\nabla \\cdot (\\rho_t v_t) = 0,\n",
    "\\end{equation}\n",
    "with $\\rho_0 = \\rho^0$ and $\\rho_1 = \\rho^1$.\n",
    "This constraint captures how the probability $\\rho_t$ evolves while being pushed along the time dependent vector field $v_t$. The Wasserstein distance is the minimal energy cost of performing this transformation from $\\rho_0$ to $\\rho_1$.\n",
    "This defines a metric on probability measures, and consequently it induces a geometry on the space of probabilities. (Here, $v_t$ is the gradient of the local transport map.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566eb91-69a2-448d-99d8-9d47ee321827",
   "metadata": {},
   "source": [
    "Pogodin, R., Cornford, J., Ghosh, A., Gidel, G., Lajoie, G., & Richards, B. A. Synaptic Weight Distributions Depend on the Geometry of Plasticity. In The Twelfth International Conference on Learning Representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f482fa-13f9-4530-af9c-08ef08fc207a",
   "metadata": {},
   "source": [
    "## Learning ... considering the Geometry of Plasticity\n",
    "\n",
    "While I was reviving my old blog and moved (few) old posts from my depracated blog to this one, I remebered while re-reading my post on Wasserstein gradient flows.... This text\n",
    "\n",
    "this was one of the shifts in my perspective moving from Eucledian geometry to Riemannian, and the importance of the geometry of the space and the associated metric. This incidentally was instrumental for the last part of my PhD.\n",
    "But also reminded me the recent work from Pogodin, Cornford et al that appeared a couple of years ago and got published in the 2024 ICLR conference discussing the importance of considering the **geometry of plasticity** to determine the limiting weight distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6812f8-2394-4620-be0a-ddd6f4a5bf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
