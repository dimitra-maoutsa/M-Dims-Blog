[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a semi-organised collection of living texts on theoretical and computational neuroscience, nonlinear dynamics, probability theory, and machine learning theory, or whatever else manages to trigger my interest. \nSome early entries are adapted relics of my PhD thesis (including those bits that didn’t survive the final edits), while others are working notes that help me understand things better and might one day become something more formal.\nNew posts will appear irregularly (when I feel like it). Old ones will get updated when I gain new insights, realise I was wrong, or I am bored and feel like procrastinating by refining them.\nExpect mostly math, neurons, and the occasional rabbit hole commentary.\nThis blog is maintained by Dimitra Maoutsa, and is powered by quarto.\nSome thumbnails have been generated by DALL·E."
  },
  {
    "objectID": "posts/22_11_02-from_pdes_to_gradient_flows.html",
    "href": "posts/22_11_02-from_pdes_to_gradient_flows.html",
    "title": "From PDEs to gradient flows for deterministic particle dynamics",
    "section": "",
    "text": "Let us consider PDEs that describe the evolution of a density \\(\\rho_t(x)\\) that evolves in time, with \\(x\\in \\mathcal{R}^D\\). We want to describe the temporal evolution of the density \\(\\rho_t(x)\\), e.g., a density of particles at location \\(x\\).\nOne fundamental equation for this is the continuity equation, which prescribes how the the density \\(\\rho_t(x)\\) evolves in time according to laws of mass conservation. In particular, the continuity equation expresses the conservation of mass by expressing that the time derivative of the density \\(\\rho_t(x)\\) plus the divergence of the product of a velocity field \\(v(x,t)\\) and the density must vanish \\[\\begin{equation}\n    \\partial_t \\rho_t(x) + \\nabla \\cdot \\left(  v(x,t) \\rho_t(x) \\right) = 0,\n\\end{equation}\\] given some initial condition \\(\\rho_0(x) = \\rho^0(x)\\). The velocity field in this equation prescribes a spatial transformation of the density as time evolves, i.e., how a density of particles starting from \\(\\rho^0(x)\\) moves according to the velocity field \\(v(x,t)\\).\nThe continuity equation admits a useful discretisation in terms of particles. We can define an associated ordinary differential equation for their evolving positions. In fact, we can consider the evolution of \\(N\\) particles in the Euclidean space, evolving according to the ODE \\[\\begin{equation}\n    \\frac{dX_i(t)}{dt} = v(X_i(t),t) ,\n\\end{equation}\\] given some initial conditions \\(X_i(0)\\).\nThere is a close correspondence between this system of ODEs (the particles) and the solutions of the PDE. In particular, if the velocity field is sufficiently nice (globally Lipschitz in space), then as long as the iniital conditions of the particles are drawn from the density representing the initial condition of the PDE, i.e. if we take the empirical measure at each of the particle locations, i.e., \\[\\begin{equation}\n    \\hat{\\rho}_0 = \\frac{1}{N} \\sum^N_{i=1} \\delta(x-X_i(0)) \\xrightarrow{N \\rightarrow \\infty} \\rho_0(x),\n\\end{equation}\\] then the evolving locations of the Dirac masses (particles) converges according to the Wasserstein metric to the continuum solution of the PDE, \\[\\begin{equation}\n    \\hat{\\rho}_t = \\frac{1}{N} \\sum^N_{i=1} \\delta(x-X_i(t)) \\xrightarrow{N \\rightarrow \\infty} \\rho_t(x).\n\\end{equation}\\]\nBecause of this close connection between the PDEs and the particle representation, a lot of PDEs have a natural discretisation in terms of particles. The PDE conserves mass, i.e. whatever the integral of the initial condition is, that integral will be preserved over time. And the particle representation preserves positivity.\nIn general this equation is a Wasserstein gradient flow for an arbitrary velocity field.\nThe difference between the transient empirical solution \\(\\hat{\\rho}_t\\) and the exact solution \\(\\rho_t\\) within the time interval \\(t \\in[0,T]\\) will be bounded by a constant weighted by the initial distance of the initial condition\n\\[\\begin{equation}\n    \\mathcal{W}_2(\\hat{\\rho}_t,\\rho_t) \\leq C_{T,\\|  \\nabla v\\|_{\\infty}} \\mathcal{W}_2(\\hat{\\rho}_0, \\rho_0).\n\\end{equation}\\]"
  },
  {
    "objectID": "posts/22_11_02-from_pdes_to_gradient_flows.html#fokker-planck-equations-as-gradient-flows",
    "href": "posts/22_11_02-from_pdes_to_gradient_flows.html#fokker-planck-equations-as-gradient-flows",
    "title": "From PDEs to gradient flows for deterministic particle dynamics",
    "section": "Fokker Planck equations as gradient flows",
    "text": "Fokker Planck equations as gradient flows\nAn equation that is a Wasserstein gradient flow and has attracted a lot of interest in the last years is the Fokker-Planck equation. It describes the evolution of a density according to a drift term \\[\\begin{equation}\n    \\partial_t \\rho_t(x) = \\nabla \\cdot \\left( \\nabla V \\rho_t(x)\\right) + \\nabla \\nabla \\rho_t(x).\n\\end{equation}\\] This equation has an associated particle method, a stochastic one, because we have the diffusion term present \\[\\begin{equation}\n    dX_t = -V(X_t)dt + \\sqrt{2} dW_t.\n\\end{equation}\\] The empirical measure represented in terms of particles will converge almost surely to the solution of the PDE.\nHowever, this PDE has a corresponding particle discretisation, where each particle evolves according to an Ordinary differential equation\n[ prof flow ode ]\nSince the density interacts with itself, the particles interact with each other through the second term.\nThis equation has a Wasserstein gradient flow structure. It is the gradient flow of the following energy \\[\\begin{equation}\n    \\mathcal{E}(\\rho) = \\int V(x) \\rho(x) dx + \\int \\rho(x) \\log \\rho(x) dx\n\\end{equation}\\] it has an external potential term, and the second term is the negative entropy. The particles are going at a direction negative of the gradient of the energy landscape for conservative systems, where the potential is small, to make the energy smaller. The diffusion term forces the density to spread out, so this term makes the entropy bigger.\nFokker-Planck equation can be viewed as a gradient flow. The central point of this idea is to define a manifold on which the Fokker-Planck system is a dynamical system on the manifold and evolving according to its gradient.\nBy understanding the convexity properties of the function \\(V(x)\\) that represents the potential, can inform us about convexity properties of the energy landscape, and from there we can recover properties of the Fokker-Planck equation, i.e. contraction of solutions, exponential convergence to the equilibrium, etc.\nThe particle solution is not a Wasserstein gradient flow of this energy. The reason for this is that I could write the PDE as a continuity type of equation \\[\\begin{equation}\n    \\partial_t \\rho_t(x) = \\nabla \\cdot \\left[ \\underbrace{( \\nabla V + \\frac{\\nabla \\rho}{\\rho})}_{\\text{velocity field:} v(x,t)} \\rho \\right]\n\\end{equation}\\] But this is a weird velocity field and for a general density the particle method will not be well defined. Due to the diffusion the instantaneous Dirac masses will not remain Dirac masses.\nThe Wasserstein space is the space of probability measures on \\(\\mathcal{R}^N\\) with the metric induced by the Wasserstein distance.\nThe seminal work of Jordan-Kinderlehrer-Otto~ established the view of the Fokker–Planck equation as a gradient flow of the Kullback Leibler divergence functional on a probability space equipped with a Wasserstein metric. The solution of the Fokker–Planck equation with drift forces arising as a gradient of a potential \\(V(x)\\), i.e., \\(f(x)=\\nabla V(x)\\) was identified as the gradient flow of the free energy with respect to the Wasserstein metric. For a gradient system, the free energy difference between two states \\(\\delta F\\) amounts to the negative entropy production times the temperature \\(\\delta F = - \\mathcal{T} \\mathcal{S}\\), where \\(\\mathcal{S}\\) stands for the entropy production. Thus this formulation may be viewed as a maximum entropy principle for the Fokker Planck.\nThe Fokker-Planck equation can be viewed as as the gradient flow in the Wasserstein metric of the relative entropy functional \\[\\begin{equation}\n    S(\\rho) = \\int_{\\mathcal{R}^d} \\rho(x) \\log\\left( \\frac{\\rho(x)}{e^{-V(x)}} \\right)dx.\n\\end{equation}\\]\nHowever, a major computational challenge of this known as JKO scheme is how to computationally efficiently compute the optimal transport cost.\nThe optimal transport yields geodesics in the Wasserstein space [cite Villani old and new]. The evolution of the probability density described by the Fokker–Planck equation amounts to the a curve in the Wasserstein space, the actual length of this curve is identified as the distance between the initial and the terminal points if this curve is a geodesic. All other curves that connect the two measures have larger dissipation. Optimal transport protocols correspond to geodesics in the Wasserstein space and can be employed in an equivalent definition of curvature."
  },
  {
    "objectID": "posts/NMA_mentoring.html",
    "href": "posts/NMA_mentoring.html",
    "title": "Succesfully mentored six project groups at NMA summer schools",
    "section": "",
    "text": "In the last 2-3 weeks I had the luck to meet (online) and mentor several young researchers, aspiring computational neuroscientists and NeuroAI researchers. I had the honor to mentor two groups on their research projects (one working on the Motor RNN project and another one working on inter-area communications using the IBL dataset) for the Neuromatch Computational Neuroscience summer course, and two pods, each with two groups, from the NeuroAI course (two groups working on biologically informed network architectures for robotic control, and two on bilogically plaussible learning algorithms). I learned so much from them over these weeks, and I hope they also gained a lot by working on their projects.\nI couldn’t be more lucky1 meeting such motivated, hardworking, and brilliant young minds. Hope our trajectories will cross again at some point in the future."
  },
  {
    "objectID": "posts/NMA_mentoring.html#footnotes",
    "href": "posts/NMA_mentoring.html#footnotes",
    "title": "Succesfully mentored six project groups at NMA summer schools",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd I call it luck, because the last time I mentored (or at least tried to mentor) a group for NMA, things went downhill, and that was definitely not NMA’s fault. Within a week after two of the mentees started following my GitHub profile, they started refusing to collaborate with the third member, and wanted to either ensure their first authorship in the upcoming micropublication, or abandon the project. Incidentally, this happened exactly at the time when I left my previous postdoc lab, at a time when some people (I don’t know who) were trying to track my whereabouts and block my path forward. So this could either be a complete coincidence that I happened to find myself in two toxic situations, originate from my behaviour, or somehow these two events could be connected. We will never know ;) As a complete coincidence, the project I was mentoring happened to use the same dataset as my main postdoc project, though it was tackling a completely different question. So this time, I was lucky enough to keep everything private until the projects were completed and we faced absolutelly no issue ;)↩︎"
  },
  {
    "objectID": "posts/21_08_03_probability_flow_dynamics.html",
    "href": "posts/21_08_03_probability_flow_dynamics.html",
    "title": "Probability flow dynamics for constraining stochastic nonlinear systems",
    "section": "",
    "text": "Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics (Gillespie and Petzold 2003), populations of animal species, biological neurons (Saarinen, Linne, and Yli-Harja 2008), and evolution (Lande, Engen, and Saether 2003),(Takahata, Ishii, and Matsuda 1975). Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales by both considering deterministic and stochastic forces affecting their state variables \\(X_t \\in  \\mathcal{R}^d\\) following\n\\[dX_t = f(X_t,t) dt  + \\sigma dW_t. \\]\nIn Eq.\\((1)\\) the drift \\(f(\\cdot,\\cdot): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) is a smooth typically nonlinear function that captures the deterministic part of the driving forces, while \\(W\\) stands for a k–dimensional (\\(k\\leq d\\)) vector of independent Wiener processes acting as white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by \\(\\sigma \\in \\mathcal{R}\\)1, and define the noise covariance as \\({D =\\sigma ^2}\\). In the following we refer to this system as the system.\nUnder multiple independent realisations, the stochastic nature of Eq.\\((1)\\) gives rise to an ensemble of trajectories starting from an initial state \\(X_0=x_0\\). This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density \\(p_t(x)\\), whose evolution is governed by the Fokker–Planck equation\n\\[\\frac{\\partial p_t(x)}{\\partial t}\n= \\nabla\\cdot \\left[- f(x,t) p_t (x) + \\frac{\\sigma^2}{2} \\nabla p_t(x)\\right]\\] \\[ \\hspace{-57pt}= {\\cal{L}}_f^\\dagger p_t(x) ,\\]\nwith initial condition \\(p_0(x) = \\delta(x-x_0)\\), and \\(\\mathcal{L}_f^\\dagger\\) denoting the Fokker–Planck operator. Due to the stochastic nature of the system of Eq.\\((1)\\), exact pinpointing of its state at some later time point \\(T\\) is in general not possible.\nYet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval. Characteristic examples include designing artificial selection strategies for population dynamics (Nourmohammad and Eksin 2021), or triggering phenotype switches during cell fate determination (Wells, Kath, and Motter 2015). Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs (Todorov 2005), (Todorov 2004). In all these settings, external system interventions become essential.\nHere, we are interested in introducing constraints \\(\\mathcal{C}\\) to the dynamics of the system of Eq.(\\(1\\)) acting within a predefined time interval \\({0 \\leq t \\leq T}\\). The set of possible constraints \\(\\mathcal{C}\\) comprises terminal \\(\\chi(X_T)\\), and/or path constraints $U(x,t), tT $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point. The path constraints $U(x,t): ^{d} $ penalise specific trajectories (paths) to render specific regions of the state space more (un)likely to be visited, while the function \\(\\chi(x): \\mathcal{R}^{d} \\rightarrow \\mathcal{R}\\) influences the terminal system state \\(X_T\\).\nTo incorporate the constraints \\(\\mathcal{C}\\) into the system, we define a modified dynamics, the controlled dynamics, through a change of probability measure of the path ensemble \\(\\mathbb{P}_f\\) induced by the uncontrolled system. More precisely, we consider the path measure \\(\\mathbb{Q}\\) (Appendix A), induced by the controlled system, as equivalent to a reweighting of paths \\(X_{0:T}\\) generated from the uncontrolled dynamics (Eq.\\((1)\\)) over the time interval \\([0,\\; T]\\). Individual path weights are thus given by the likelihood ratio (Radon–Nikodym derivative)\n\\[\\frac{d\\mathbb{Q}}{d\\mathbb{P}_f} (X_{0:T}) = \\frac{\\chi(X_T)}{Z} \\exp\\left[- \\int_0^T U(X_t,t) dt \\right],\\]\nwhere \\(Z\\) denotes the normalising constant\n\\[Z = \\Bigg \\langle \\chi(X_T) \\exp\\left(- \\int_0^T U(X_t,t) dt \\right) \\Bigg\\rangle_{\\mathbb{P}_f},\\]\nand \\(\\langle \\cdot \\rangle_{\\mathbb{P}_f}\\) denotes the expectation over paths of the uncontrolled system.\nAccording to the Girsanov’s theorem, the controlled process defined by the weights of Eq.\\((4)\\) is also a diffusion process with the same diffusion constant \\(\\sigma\\), but with a modified, time-dependent drift function \\(g(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) (Girsanov 1960), (Øksendal 2003). Thus, we express the controlled dynamics as a time- and state- dependent perturbation \\(u(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) of the deterministic forces \\(f(x,t)\\) acting on the system\n\\[ dX_t = \\Big( f(X_t,t)   + u(X_t,t) \\Big) \\; dt + \\sigma dW_t \\] \\[= \\hspace{25pt}g(X_t,t)\\;\\hspace{5pt} dt \\hspace{30pt}+ \\sigma dW_t.\\]\nOur goal is to identify the optimal time- and state-dependent interventions \\(u(x,t)\\) that minimise intervention costs and path constraints captured by the cost function\n\\[S(x,u,t) =  \\frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),\\]\nwhile also drive the system towards a predefined target state \\(x^*\\) by time \\(T\\), if a terminal constraint is pertinent. The first part of the cost function penalises large intervention values \\(u(x,t)\\), with \\(H \\in \\mathcal{R}^{d \\times d}\\) determining the cost of intervention along each system dimension, whereas the path cost \\(U(x,t)\\) constrains the transient behaviour of the system.\nSolutions of this type of stochastic control problems rest on the Bellman’s principle of optimality, according to which an optimal solution over an interval \\([0,\\;T]\\) consists of optimal sub-solutions over the respective sub-intervals \\([t',\\;T]\\) with later starting times \\(t'\\), and appropriate initial conditions (Bellman 1956). This sequence of sub-problems with interdependent initial conditions requires the cost function \\(S(x,u,t)\\) to be minimized over the entire time interval \\([0,\\;T]\\). Therefore, here, we minimize the total expected cost in that interval defined as the sum of the terminal cost \\(\\chi(X_T)\\) and the time integrated path and intervention costs\n\\[ J(x,t=0) = \\min_{u} \\Big\\langle  \\int_{t=0}^T S(x,u,t') \\,  dt' -  \\ln \\chi(X_T) \\Big\\rangle_{\\mathbb{Q}}. \\] In Eq.\\((6)\\), the brackets \\(\\langle \\cdot \\rangle_{\\mathbb{Q}}\\) denote the expectation over the entire path probability measure \\(\\mathbb{Q}\\).\nTo establish the optimality of the interventions, we demand the cost functional \\(J(x,t)\\) to follow the Hamilton–Jacobi–Bellman (HJB) equation,\n\\[  -\\frac{\\partial}{\\partial t} J(X_t,t) = \\min_u \\Bigg[ \\frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)\\] \\[\\hspace{95pt} + g(X_t,t) \\nabla_x J(X_t,t) + \\frac{1}{2} \\text{Tr}[D \\frac{\\partial^2}{\\partial x^2} J(X_t,t)]  \\Bigg] \\] a nonlinear partial differential equation (PDE) with a terminal condition \\(J(x,T)= \\ln \\chi(X_T)\\), which is, therefore, solved backwards in time. The gradient of the solution of this equation\n\\[u^*(x,t) = - H^{-1}  \\nabla J(x,t),\\]\nprovides the optimal state- and time-dependent interventions for the considered system with constraints \\(\\mathcal{C}\\). Yet, without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension.\nTo simplify matters, we linearise the Hamilton–Jacobi–Bellman equation by employing a logarithmic variable transformation, \\(J(x,t) = - \\log( \\phi(x,t))\\), proposed initially by Nelson in (Nelson 1967), and introduced in the context of stochastic control by Fleming in (Fleming 1977) (Hopf-Cole transform). This requires the minimal assumption of the control costs \\(H\\) and noise covariance \\(D\\) being inversely proportional along each state dimension, \\(H \\propto D^{-1}=\\sigma^{-2}\\), known in the literature as the path integral control condition (Kappen 2005).\nThe logarithmic variable transformation allows us to express the resulting controlled drift\n\\[g(x,t)  = f(x,t) +  \\sigma^2 \\nabla \\ln \\phi(x,t), \\]\nin terms of the solution \\(\\phi_t(x) \\doteq\\phi(x,t)\\) of a linear backward partial differential equation\n\\[\\frac{\\partial \\phi_t(x)}{\\partial t} + {\\cal{L}}_f \\phi_t(x) - U(x,t) \\phi_t(x) = 0 ,\\]\nwith terminal condition \\(\\phi_T(x) = \\chi(X_T)\\), and with \\(\\mathcal{L}_f\\) denoting theadjoint Fokker–Planck operator."
  },
  {
    "objectID": "posts/21_08_03_probability_flow_dynamics.html#dynamics-of-constrained-densities",
    "href": "posts/21_08_03_probability_flow_dynamics.html#dynamics-of-constrained-densities",
    "title": "Probability flow dynamics for constraining stochastic nonlinear systems",
    "section": "",
    "text": "Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics (Gillespie and Petzold 2003), populations of animal species, biological neurons (Saarinen, Linne, and Yli-Harja 2008), and evolution (Lande, Engen, and Saether 2003),(Takahata, Ishii, and Matsuda 1975). Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales by both considering deterministic and stochastic forces affecting their state variables \\(X_t \\in  \\mathcal{R}^d\\) following\n\\[dX_t = f(X_t,t) dt  + \\sigma dW_t. \\]\nIn Eq.\\((1)\\) the drift \\(f(\\cdot,\\cdot): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) is a smooth typically nonlinear function that captures the deterministic part of the driving forces, while \\(W\\) stands for a k–dimensional (\\(k\\leq d\\)) vector of independent Wiener processes acting as white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by \\(\\sigma \\in \\mathcal{R}\\)1, and define the noise covariance as \\({D =\\sigma ^2}\\). In the following we refer to this system as the system.\nUnder multiple independent realisations, the stochastic nature of Eq.\\((1)\\) gives rise to an ensemble of trajectories starting from an initial state \\(X_0=x_0\\). This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density \\(p_t(x)\\), whose evolution is governed by the Fokker–Planck equation\n\\[\\frac{\\partial p_t(x)}{\\partial t}\n= \\nabla\\cdot \\left[- f(x,t) p_t (x) + \\frac{\\sigma^2}{2} \\nabla p_t(x)\\right]\\] \\[ \\hspace{-57pt}= {\\cal{L}}_f^\\dagger p_t(x) ,\\]\nwith initial condition \\(p_0(x) = \\delta(x-x_0)\\), and \\(\\mathcal{L}_f^\\dagger\\) denoting the Fokker–Planck operator. Due to the stochastic nature of the system of Eq.\\((1)\\), exact pinpointing of its state at some later time point \\(T\\) is in general not possible.\nYet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval. Characteristic examples include designing artificial selection strategies for population dynamics (Nourmohammad and Eksin 2021), or triggering phenotype switches during cell fate determination (Wells, Kath, and Motter 2015). Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs (Todorov 2005), (Todorov 2004). In all these settings, external system interventions become essential.\nHere, we are interested in introducing constraints \\(\\mathcal{C}\\) to the dynamics of the system of Eq.(\\(1\\)) acting within a predefined time interval \\({0 \\leq t \\leq T}\\). The set of possible constraints \\(\\mathcal{C}\\) comprises terminal \\(\\chi(X_T)\\), and/or path constraints $U(x,t), tT $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point. The path constraints $U(x,t): ^{d} $ penalise specific trajectories (paths) to render specific regions of the state space more (un)likely to be visited, while the function \\(\\chi(x): \\mathcal{R}^{d} \\rightarrow \\mathcal{R}\\) influences the terminal system state \\(X_T\\).\nTo incorporate the constraints \\(\\mathcal{C}\\) into the system, we define a modified dynamics, the controlled dynamics, through a change of probability measure of the path ensemble \\(\\mathbb{P}_f\\) induced by the uncontrolled system. More precisely, we consider the path measure \\(\\mathbb{Q}\\) (Appendix A), induced by the controlled system, as equivalent to a reweighting of paths \\(X_{0:T}\\) generated from the uncontrolled dynamics (Eq.\\((1)\\)) over the time interval \\([0,\\; T]\\). Individual path weights are thus given by the likelihood ratio (Radon–Nikodym derivative)\n\\[\\frac{d\\mathbb{Q}}{d\\mathbb{P}_f} (X_{0:T}) = \\frac{\\chi(X_T)}{Z} \\exp\\left[- \\int_0^T U(X_t,t) dt \\right],\\]\nwhere \\(Z\\) denotes the normalising constant\n\\[Z = \\Bigg \\langle \\chi(X_T) \\exp\\left(- \\int_0^T U(X_t,t) dt \\right) \\Bigg\\rangle_{\\mathbb{P}_f},\\]\nand \\(\\langle \\cdot \\rangle_{\\mathbb{P}_f}\\) denotes the expectation over paths of the uncontrolled system.\nAccording to the Girsanov’s theorem, the controlled process defined by the weights of Eq.\\((4)\\) is also a diffusion process with the same diffusion constant \\(\\sigma\\), but with a modified, time-dependent drift function \\(g(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) (Girsanov 1960), (Øksendal 2003). Thus, we express the controlled dynamics as a time- and state- dependent perturbation \\(u(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d\\) of the deterministic forces \\(f(x,t)\\) acting on the system\n\\[ dX_t = \\Big( f(X_t,t)   + u(X_t,t) \\Big) \\; dt + \\sigma dW_t \\] \\[= \\hspace{25pt}g(X_t,t)\\;\\hspace{5pt} dt \\hspace{30pt}+ \\sigma dW_t.\\]\nOur goal is to identify the optimal time- and state-dependent interventions \\(u(x,t)\\) that minimise intervention costs and path constraints captured by the cost function\n\\[S(x,u,t) =  \\frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),\\]\nwhile also drive the system towards a predefined target state \\(x^*\\) by time \\(T\\), if a terminal constraint is pertinent. The first part of the cost function penalises large intervention values \\(u(x,t)\\), with \\(H \\in \\mathcal{R}^{d \\times d}\\) determining the cost of intervention along each system dimension, whereas the path cost \\(U(x,t)\\) constrains the transient behaviour of the system.\nSolutions of this type of stochastic control problems rest on the Bellman’s principle of optimality, according to which an optimal solution over an interval \\([0,\\;T]\\) consists of optimal sub-solutions over the respective sub-intervals \\([t',\\;T]\\) with later starting times \\(t'\\), and appropriate initial conditions (Bellman 1956). This sequence of sub-problems with interdependent initial conditions requires the cost function \\(S(x,u,t)\\) to be minimized over the entire time interval \\([0,\\;T]\\). Therefore, here, we minimize the total expected cost in that interval defined as the sum of the terminal cost \\(\\chi(X_T)\\) and the time integrated path and intervention costs\n\\[ J(x,t=0) = \\min_{u} \\Big\\langle  \\int_{t=0}^T S(x,u,t') \\,  dt' -  \\ln \\chi(X_T) \\Big\\rangle_{\\mathbb{Q}}. \\] In Eq.\\((6)\\), the brackets \\(\\langle \\cdot \\rangle_{\\mathbb{Q}}\\) denote the expectation over the entire path probability measure \\(\\mathbb{Q}\\).\nTo establish the optimality of the interventions, we demand the cost functional \\(J(x,t)\\) to follow the Hamilton–Jacobi–Bellman (HJB) equation,\n\\[  -\\frac{\\partial}{\\partial t} J(X_t,t) = \\min_u \\Bigg[ \\frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)\\] \\[\\hspace{95pt} + g(X_t,t) \\nabla_x J(X_t,t) + \\frac{1}{2} \\text{Tr}[D \\frac{\\partial^2}{\\partial x^2} J(X_t,t)]  \\Bigg] \\] a nonlinear partial differential equation (PDE) with a terminal condition \\(J(x,T)= \\ln \\chi(X_T)\\), which is, therefore, solved backwards in time. The gradient of the solution of this equation\n\\[u^*(x,t) = - H^{-1}  \\nabla J(x,t),\\]\nprovides the optimal state- and time-dependent interventions for the considered system with constraints \\(\\mathcal{C}\\). Yet, without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension.\nTo simplify matters, we linearise the Hamilton–Jacobi–Bellman equation by employing a logarithmic variable transformation, \\(J(x,t) = - \\log( \\phi(x,t))\\), proposed initially by Nelson in (Nelson 1967), and introduced in the context of stochastic control by Fleming in (Fleming 1977) (Hopf-Cole transform). This requires the minimal assumption of the control costs \\(H\\) and noise covariance \\(D\\) being inversely proportional along each state dimension, \\(H \\propto D^{-1}=\\sigma^{-2}\\), known in the literature as the path integral control condition (Kappen 2005).\nThe logarithmic variable transformation allows us to express the resulting controlled drift\n\\[g(x,t)  = f(x,t) +  \\sigma^2 \\nabla \\ln \\phi(x,t), \\]\nin terms of the solution \\(\\phi_t(x) \\doteq\\phi(x,t)\\) of a linear backward partial differential equation\n\\[\\frac{\\partial \\phi_t(x)}{\\partial t} + {\\cal{L}}_f \\phi_t(x) - U(x,t) \\phi_t(x) = 0 ,\\]\nwith terminal condition \\(\\phi_T(x) = \\chi(X_T)\\), and with \\(\\mathcal{L}_f\\) denoting theadjoint Fokker–Planck operator."
  },
  {
    "objectID": "posts/21_08_03_probability_flow_dynamics.html#footnotes",
    "href": "posts/21_08_03_probability_flow_dynamics.html#footnotes",
    "title": "Probability flow dynamics for constraining stochastic nonlinear systems",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the sake of brevity, we consider here a state independent diffusion, but the formalism easily generalises for a state dependent diffusion \\(\\sigma(x)\\), as outlined in the Appendix.}↩︎"
  },
  {
    "objectID": "posts/Flatiron_CCNJunior_Theoretical_Neuro.html",
    "href": "posts/Flatiron_CCNJunior_Theoretical_Neuro.html",
    "title": "Gave a talk on my recent work at the Junior Theoretical Neuroscientist’s Workshop",
    "section": "",
    "text": "I had the honor to give a talk on my recent work at the Junior Theoretical Neuroscientist’s Workshop[ official website ] organised by the Flatiron Institute. Was great to be given the opportunity to get feedback on my work and reconect with some stellar junior theoretical neuroscientists."
  },
  {
    "objectID": "posts/Grad_flows.html",
    "href": "posts/Grad_flows.html",
    "title": "Wasserstein gradient flows",
    "section": "",
    "text": "Given some energy functional \\(\\mathcal{E}(\\rho)\\) in some probability space \\(\\mathcal{P}(\\Omega)\\) with some metric \\(\\mathcal{G}(\\rho))\\), \\((\\mathcal{P}(\\Omega), \\mathcal{G}(\\rho))\\), a gradient flow is defined as the inverse metric times the differential of the energy function \\[\\begin{equation}\n    \\partial_t \\rho_t = -\\mathcal{G}(\\rho_t)^{-1} \\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t}.\n\\end{equation}\\] Here, \\(\\rho_t\\) is a distribution at time \\(t\\).\nIntuitively, this means that the considered system of equations follows the trajectory of steepest descend on the energy functional \\(\\mathcal{E}(\\rho)\\). To define this steepest descend we need to define the notion of the gradient. The gradient, in turn, depends on the selected geometry of the space and is computed according to the selected metric.\nIf we consider for energy functional the Kullback Leibler divergence \\(D_{KL}\\), and for (information) metric the Wasserstein metric \\(\\mathcal{W}\\), the considered gradient flow, known as Wasserstein gradient flow, forms the Fokker-Planck equation.\nIn this case the metric inverse is \\(\\nabla \\cdot \\rho_t \\nabla\\), and we can derive the Fokker–Planck equation as follows:\n\\[\\begin{align}\n\\partial_t \\rho_t &= - \\text{grad}^{\\mathcal{W}} D_{KL}(\\rho_t ||\\rho_{ss})\\\\\n&= \\nabla \\cdot \\left(  \\rho_t \\nabla \\left( f + \\log \\rho_t +1 \\right)  \\right)\\\\\n&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\nabla \\cdot \\nabla \\rho_t\\\\\n&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\Delta \\rho_t.\n\\end{align}\\]\nIn the above equation we have considered that the stationary density is given by \\(\\rho_{ss} \\propto e^{-f}\\), and that the differential of \\(\\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t} = \\log \\rho + f\\).\nBy considering the Benamou-Brenier formulation (Benamou and Brenier 2000),(Ambrosio et al. 2003) of the Fokker-Planck dynamics we can obtain a better understanding on how the selected geometry (and metric) of the probability space influences the gradient flow dynamics. According to the Benamou-Brenier formalism the gradient flow dynamics for the Fokker-Planck equation has the following optimal transport interpretation: It describes a search over all possible vector fields \\(v_t\\) that will transport probability mass from \\(\\rho_0\\) to \\(\\rho_1\\), with the Wasserstein distance capturing the minimum possible cost of this transfer. Given two probability distributions \\(\\rho_0\\) and \\(\\rho_1\\), we define this distance to be the minimum of the integral of the norm of the vector field \\(v_t\\) \\[\\begin{equation}\nd^2_{OT} (\\rho_0, \\rho_1) = \\inf \\limits_{\\rho_t, v_t} \\int_0^1 \\| v_t \\|^2_{L^2(\\rho_t)} dt = \\mathcal{W}^2_2 (\\rho_0,\\rho_1),\n\\end{equation}\\] under the constraint that the transient probability distribution \\(\\rho_t\\) fulfils the continuity equation \\[\\begin{equation}\n    \\partial_t \\rho_t + \\nabla \\cdot (\\rho_t v_t) = 0,\n\\end{equation}\\] with \\(\\rho_0 = \\rho^0\\) and \\(\\rho_1 = \\rho^1\\). This constraint captures how the probability \\(\\rho_t\\) evolves while being pushed along the time dependent vector field \\(v_t\\). The Wasserstein distance is the minimal energy cost of performing this transformation from \\(\\rho_0\\) to \\(\\rho_1\\). This defines a metric on probability measures, and consequently it induces a geometry on the space of probabilities. (Here, \\(v_t\\) is the gradient of the local transport map.)"
  },
  {
    "objectID": "posts/Grad_flows.html#what-is-a-gradient-flow-in-the-probability-space",
    "href": "posts/Grad_flows.html#what-is-a-gradient-flow-in-the-probability-space",
    "title": "Wasserstein gradient flows",
    "section": "",
    "text": "Given some energy functional \\(\\mathcal{E}(\\rho)\\) in some probability space \\(\\mathcal{P}(\\Omega)\\) with some metric \\(\\mathcal{G}(\\rho))\\), \\((\\mathcal{P}(\\Omega), \\mathcal{G}(\\rho))\\), a gradient flow is defined as the inverse metric times the differential of the energy function \\[\\begin{equation}\n    \\partial_t \\rho_t = -\\mathcal{G}(\\rho_t)^{-1} \\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t}.\n\\end{equation}\\] Here, \\(\\rho_t\\) is a distribution at time \\(t\\).\nIntuitively, this means that the considered system of equations follows the trajectory of steepest descend on the energy functional \\(\\mathcal{E}(\\rho)\\). To define this steepest descend we need to define the notion of the gradient. The gradient, in turn, depends on the selected geometry of the space and is computed according to the selected metric.\nIf we consider for energy functional the Kullback Leibler divergence \\(D_{KL}\\), and for (information) metric the Wasserstein metric \\(\\mathcal{W}\\), the considered gradient flow, known as Wasserstein gradient flow, forms the Fokker-Planck equation.\nIn this case the metric inverse is \\(\\nabla \\cdot \\rho_t \\nabla\\), and we can derive the Fokker–Planck equation as follows:\n\\[\\begin{align}\n\\partial_t \\rho_t &= - \\text{grad}^{\\mathcal{W}} D_{KL}(\\rho_t ||\\rho_{ss})\\\\\n&= \\nabla \\cdot \\left(  \\rho_t \\nabla \\left( f + \\log \\rho_t +1 \\right)  \\right)\\\\\n&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\nabla \\cdot \\nabla \\rho_t\\\\\n&= \\nabla \\cdot \\left( \\rho_t \\nabla f\\right) + \\Delta \\rho_t.\n\\end{align}\\]\nIn the above equation we have considered that the stationary density is given by \\(\\rho_{ss} \\propto e^{-f}\\), and that the differential of \\(\\frac{\\delta \\mathcal{E}(\\rho_t)}{\\delta \\rho_t} = \\log \\rho + f\\).\nBy considering the Benamou-Brenier formulation (Benamou and Brenier 2000),(Ambrosio et al. 2003) of the Fokker-Planck dynamics we can obtain a better understanding on how the selected geometry (and metric) of the probability space influences the gradient flow dynamics. According to the Benamou-Brenier formalism the gradient flow dynamics for the Fokker-Planck equation has the following optimal transport interpretation: It describes a search over all possible vector fields \\(v_t\\) that will transport probability mass from \\(\\rho_0\\) to \\(\\rho_1\\), with the Wasserstein distance capturing the minimum possible cost of this transfer. Given two probability distributions \\(\\rho_0\\) and \\(\\rho_1\\), we define this distance to be the minimum of the integral of the norm of the vector field \\(v_t\\) \\[\\begin{equation}\nd^2_{OT} (\\rho_0, \\rho_1) = \\inf \\limits_{\\rho_t, v_t} \\int_0^1 \\| v_t \\|^2_{L^2(\\rho_t)} dt = \\mathcal{W}^2_2 (\\rho_0,\\rho_1),\n\\end{equation}\\] under the constraint that the transient probability distribution \\(\\rho_t\\) fulfils the continuity equation \\[\\begin{equation}\n    \\partial_t \\rho_t + \\nabla \\cdot (\\rho_t v_t) = 0,\n\\end{equation}\\] with \\(\\rho_0 = \\rho^0\\) and \\(\\rho_1 = \\rho^1\\). This constraint captures how the probability \\(\\rho_t\\) evolves while being pushed along the time dependent vector field \\(v_t\\). The Wasserstein distance is the minimal energy cost of performing this transformation from \\(\\rho_0\\) to \\(\\rho_1\\). This defines a metric on probability measures, and consequently it induces a geometry on the space of probabilities. (Here, \\(v_t\\) is the gradient of the local transport map.)"
  },
  {
    "objectID": "posts/Low_rank_tensors.html",
    "href": "posts/Low_rank_tensors.html",
    "title": "Low tensor rank learning of neural dynamics",
    "section": "",
    "text": "Back in September 2023, after the Bernstein Conference, I came back from Alex Cayco-Gajic’s workshop talk quite inspired. The low tensor rank framework she presented (work together with Arthur Pellegrino and Angus Chadwick Pellegrino, Cayco Gajic, and Chadwick (2023)) had struck me as one of the more conceptually elegant approaches to track how neural population dynamics change over learning. I very enthusiastically shared my excitement in the internal post-Bernstein group meeting, as one does when ideas resonate1.\n\n\n\nphoto from my presentation containing photo of Alex’s presentation :)\n\n\nIt turned out that sharing my excitement about someone else’s work2 didn’t land equally well with everyone in the room, but that’s life. The dynamics that followed are perhaps best saved for a more informal conversation.\nA few months later, in December 2023, I noticed the call for the ICLR 2024 blogpost track, and thought this would be a great opportunity to spotlight this work. I began drafting a piece, but for a mix of personal and political reasons (and admittedly, some competing deadlines), I set it aside3.\nSince I am still excited about this work, stay tuned here, I will soon revive this post.\nIn the meantime, I recommend going straight to the source, it’s a great read."
  },
  {
    "objectID": "posts/Low_rank_tensors.html#footnotes",
    "href": "posts/Low_rank_tensors.html#footnotes",
    "title": "Low tensor rank learning of neural dynamics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI even reached out a few days later to congratulate her on the talk (a breach of my usually well-fortified social inertia) and to ask for a copy of a paper I couldn’t access.↩︎\nespecially that specific someone↩︎\n\n\n\nICLR blogpost track pull request\n\n\n↩︎"
  },
  {
    "objectID": "posts/Satelite_StatPhys29.html",
    "href": "posts/Satelite_StatPhys29.html",
    "title": "Presented my recent work at a Satellite meeting of StatPhys29",
    "section": "",
    "text": "A few days ago I presented my recent work at a Satellite StatPhys29 meeting on Collective Dynamics and Information Processing in Neural Systems[ official website ] that took place in Venice, Italy.\n\nI will come back with highlights, because at least two very talened young researchers need to be mentioned!"
  },
  {
    "objectID": "posts/Not_in_photo.html",
    "href": "posts/Not_in_photo.html",
    "title": "Off camera, still there",
    "section": "",
    "text": "Lately, I’ve come to realize that when certain things are left unsaid openly un-documented, well-meaning people1 will bend the story according to how it fits their narrative, regardless of what actually happened. For more than a year I am fighting against someone who systematically tries to damage my credibility.\nBecause of that, I’ve found myself in the uncomfortable position of having to share more personal details online than I normally would, just to preempt false narratives or quiet insinuations2.\nOne such case involves a recent group photo uploaded from a retreat organized in April 2024 by my previous research group. I am not pictured in that photo. And given past patterns, I expect this absence will be used, subtly or not, to imply that I didn’t participate in the retreat at all.\nSo, here is what actually happened.\nThe retreat took place from April 17–19, 2024. I was actively involved: I prepared a flash talk on my own work on identifying plasticity rules that explain differencial responses on visual stimuli depedning on familiarity, and co-prepared a joint talk with my colleagues Matt Getz and Pablo Crespo on our low-rank learning framework (presentation). First part was covered by matt, second by myself, and third by Pablo3.\nJust five days later, on April 24, I was scheduled to give a talk at the Flatiron Institute in New York (see here) on a completely different project (an independent one), this one was a continuation of my PhD work, focused on inference of latent stochastic low-dimensional dynamics from spiking neural activity.\nAs you can imagine, time was tight. I would return on Friday 19th evening home, and then depart on Monday 22th of April for New York. On April 18th, the group went for a walk, after which the photo in question was taken. I stayed back in the seminar room to prepare for my upcoming talk. So, obviously I am not in the photo, not because I was not in the retreat, but because I did not have free time for a walk4. In fact, we even joked at the time that one of the window reflections in the uncropped version of the picture looked vaguely like a human silhouette, so we could always say I was in the photo, just inside the building :).\nHere is a message I later found from my former colleague, Betsy Herbert, calling me down to join the group photo. I did not see it at the time, my phone was on silent, as it almost always is."
  },
  {
    "objectID": "posts/Not_in_photo.html#footnotes",
    "href": "posts/Not_in_photo.html#footnotes",
    "title": "Off camera, still there",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor not so well-meaning ;)↩︎\nFor instance, in May 2024, the administrator responsible for handling my PhD documentation at my awarding institution contacted me to ask why people had recently reached out to verify, whether I had in fact earned my doctoral degree. This was puzzling to me, as my thesis had already been officially published online since December 2023 [thesis], I was actively holding a postdoctoral position, and even before I joined that lab, I had received an official preliminary certificate confirming the successful completion of my PhD with summa cum laude, with only remaining step the formal uploading of my thesis in the library, a purelly procedural step, not a condition for the degree itself. There was no indication whatsoever that the final degree could be withheld/not awarded etc. Indeed, when I eventually received the final diploma in January 2024, the document was dated early April 2023 (just a couple of days after my defense) [degree], aligning with the completion timeline. Nonetheless, during that period, when I was applying for postdoctoral positions and grants, and was in conversation with several labs, it became clear that someone had actively seeded doubts or vague insinuations suggesting, that I am leaving my postdoctoral lab because I do not have a PhD or some other degree. In the meanwhile, getting hired for my postdoc required submitting all my academic degrees, even my high school diploma, and both my first EE degree thesis [not so proud but here it is] and my doctoral thesis [PhD thesis] are available online ¯_(ツ)_/¯.↩︎\nThis was work done for the Master’s thesis of Pablo, who was co-supervised by me and matt. Pablo was performing the computations and was also providing ideas, and me and matt both were shaping the scope of the project and were formulating the specific questions Pablo tackled.↩︎\nFortunately, the talk wasn’t on work-life balance, because I’m clearly still working on that :)↩︎"
  },
  {
    "objectID": "posts/The_Brain_Conferences.html",
    "href": "posts/The_Brain_Conferences.html",
    "title": "Attended the Brain Conference: Frontiers of Theoretical Neuroscience and got a travel award",
    "section": "",
    "text": "A couple of weeks ago I had the honour to attend and present my recent work at the Brain Conference: Frontiers of Theoretical Neuroscience [ official website ] that took place in Rungsted Kyst in Denmark. I was also fortunate enough to get awarded a travel scholarship to participate.\nThe Brain Conferences are a series of conferences on neuroscience organised by the Lundbeck foundation taking place bi-annually, usually at Rungstedgaard in the east of Denmark1. This iteration was organised by Larry Abbott, Ila Fiete, and Haim Sompolinsky and was focused on Theoretical Neuroscience.\nOne of the highlights of the conference for me was the poster by the very talented Samuel Liebana from UCL (see picture below), presenting his recent paper on how dopamine dynamics explain the emergence of different behavioural strategies in mice.\nI got really excited about this work, not only because incidentally it happened to be the very first poster I visited in that meeting, but also because it is very closely related to a project I’ve been developing and pitching since December 2024. The idea is to study learning dynamics in a continual learning setting and explain how prior structure resulting from previously learned task explains the emergence of diverse behavioural strategies.\nAt the time, the researchers I reached out to didn’t seem especially interested in the idea, or so it seemed from their reactions. But perhaps now, with growing experimental momentum in this direction, interest will be rekindled, and people will get more easily convinced."
  },
  {
    "objectID": "posts/The_Brain_Conferences.html#footnotes",
    "href": "posts/The_Brain_Conferences.html#footnotes",
    "title": "Attended the Brain Conference: Frontiers of Theoretical Neuroscience and got a travel award",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt that part of Denmark that is technically Sweden.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M Dims Blog",
    "section": "",
    "text": "Succesfully mentored six project groups at NMA summer schools\n\n\n\nnews\n\n\n\nthey aced it\n\n\n\n\n\nJul 26, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nGave a talk on my recent work at the Junior Theoretical Neuroscientist’s Workshop\n\n\n\nnews\n\n\n\norganised by Simons Foundation and Flatiron\n\n\n\n\n\nJul 12, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nPresented my recent work at a Satellite meeting of StatPhys29\n\n\n\nnews\n\n\n\n\n\n\n\n\nJul 7, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nAttended the Brain Conference: Frontiers of Theoretical Neuroscience and got a travel award\n\n\n\nnews\n\n\n\n\n\n\n\n\nJun 23, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nLow tensor rank learning of neural dynamics\n\n\n\nblog\n\n\n\nor how to track changes in collective dynamics during learning (coming soon)\n\n\n\n\n\nMay 25, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nOff camera, still there\n\n\n\nblog\n\n\n\nFilling in some gaps\n\n\n\n\n\nApr 8, 2025\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nFrom PDEs to gradient flows for deterministic particle dynamics\n\n\n\nblog\n\njupyter\n\n\n\nIntroduction to deterministic particle methods for PDEs. (adapted text from notes of my PhD thesis - will be updated)\n\n\n\n\n\nNov 2, 2022\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nWasserstein gradient flows\n\n\n\nblog\n\n\n\nUnderstanding the JKO scheme (adapted text from my PhD thesis)\n\n\n\n\n\nApr 4, 2022\n\n\nDimitra Maoutsa\n\n\n\n\n\n\n\n\n\n\n\n\nProbability flow dynamics for constraining stochastic nonlinear systems\n\n\n\nblog\n\njupyter\n\n\n\nDetailed description of Deterministic Particle Flow control of (upcoming paper) on controling stochastic nonlinear systems by deterministacally perturbing their dynamics.\n\n\n\n\n\nAug 3, 2021\n\n\nDimitra Maoutsa\n\n\n\n\n\nNo matching items"
  }
]